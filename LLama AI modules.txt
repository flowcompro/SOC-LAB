https://github.com/ollama/ollama

For a ubuntu install do the following
curl -fsSL https://ollama.com/install.sh | sh

you can run any of the ollama AI varios modules

I use
ollama run llama2-uncensored

to install the gui 




I did a web gui instead.
https://github.com/liltom-eth/llama2-webui/blob/main/README.md

git clone https://github.com/liltom-eth/llama2-webui.git
cd llama2-webui
pip install -r requirements.txt


python app.py  to start the web gui
then goto localhost:7860

--------------------------------------------------------

Ollama github
https://github.com/ollama/ollama

Open a ubuntu shell in windows

install wsl in windows - powershell with admin -  wsl --install

curl -fsSL https://ollama.com/install.sh | sh


to run the ai just run the command
ollama run (MODEL NAME)



example
ollama run llama
ollama run llama2
ollama run mistral
ollama run dolphin-phi
ollama run phi
ollama run neural-chat
ollama run starling-lm
ollama run codellama
ollama run llama2-uncensored
ollama run llama2:13b
ollama run llama2:70b
ollama run orca-mini
ollama run vicuna
ollama run llava
ollama run gemma:2b
ollama run gemma:7b

Model	Parameters	Size	Download
Llama 2	7B	3.8GB	ollama run llama2
Mistral	7B	4.1GB	ollama run mistral
Dolphin Phi	2.7B	1.6GB	ollama run dolphin-phi
Phi-2	2.7B	1.7GB	ollama run phi
Neural Chat	7B	4.1GB	ollama run neural-chat
Starling	7B	4.1GB	ollama run starling-lm
Code Llama	7B	3.8GB	ollama run codellama
Llama 2 Uncensored	7B	3.8GB	ollama run llama2-uncensored
Llama 2 13B	13B	7.3GB	ollama run llama2:13b
Llama 2 70B	70B	39GB	ollama run llama2:70b
Orca Mini	3B	1.9GB	ollama run orca-mini
Vicuna	7B	3.8GB	ollama run vicuna
LLaVA	7B	4.5GB	ollama run llava
Gemma	2B	1.4GB	ollama run gemma:2b
Gemma	7B	4.8GB	ollama run gemma:7b